## Hello üëã
I am Ryuto, a PhD candidate at the [Institute of Science Tokyo](https://www.isct.ac.jp/en) (Formerly Tokyo Tech), advised by Prof. [Naoaki Okazaki](https://www.chokkan.org/index.en.html). Currently, I am visiting the [UPenn NLP](https://nlp.cis.upenn.edu/), hosted by Prof. [Chris Callison-Burch](https://www.cis.upenn.edu/~ccb/). I also work with Prof. [Preslav Nakov](https://mbzuai.ac.ae/study/faculty/preslav-nakov/) from [MBZUAI NLP](https://mbzuai.ac.ae/research-department/natural-language-processing-department/). In addition to my PhD research, I am involved as an advisor for a [startup](https://3keigo.com/) on multi-lingual text generation.


I am interested in the discrepancy between human writing and LLM generation, aiming to understand and enhance LLM generative capabilities. To explore this, I have mainly been working on two key aspects:
1.  üîé **Detecting LLM-generated texts**
- **Robustness.** How can we improve the robustness of detectors in the wild? [[AAAI'24]](https://arxiv.org/pdf/2307.11729)
- **Interpretability.** How can we offer detection results to lay users more reliably?  [[In submission]](https://www.arxiv.org/pdf/2502.11336), How well can people detect LLM texts? What are the clues? [[In submission]](https://arxiv.org/pdf/2502.11614)
2. ‚úçÔ∏è **Harnessing LLMs for better generation**
- **Prompting.** How can we instruct LLMs to unlock their generative capabilities, narrowing the gap between human writing and LLM generation? [[EMNLP'24 Findings]](https://arxiv.org/pdf/2311.08369)
- **Evaluation.** How can we make LLM-as-a-judge more reliable? [[ACL'24 Findings]](https://arxiv.org/pdf/2402.15987)


üì¢ **Actively looking for research internships starting in (Summer | Fall | Winter) 2025.**

## Contact
- Personal Website: [sites.google.com/view/ryutokoike/](https://sites.google.com/view/ryutokoike/)
- Twitter: [@sponddd](https://x.com/sponddd)
- email: my_first_name.my_last_name[at]nlp.c.titech.ac.jp
