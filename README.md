## Hi there ðŸ‘‹
I am a CS PhD candidate at [Tokyo Institute of Technology](https://www.titech.ac.jp/english), advised by [Naoaki Okazaki](https://www.chokkan.org/index.en.html). My expected graduation date is March 2026. Currently, I am visiting the UPenn NLP, hosted by [Chris Callison-Burch](https://www.cis.upenn.edu/~ccb/). I also work with [Preslav Nakov](https://mbzuai.ac.ae/study/faculty/preslav-nakov/) from MBZUAI.

I work on AI safety, specifically improving the safety of large language models (LLMs) from various perspectives, including:
- Detecting texts generated by LLMs, particularly in increasing its robustness against adversarial attacks in the wild, like [OUTFOX (AAAI 2024)](https://arxiv.org/abs/2307.11729);[How You Prompt Matters (Findings of EMNLP 2024)](https://arxiv.org/abs/2311.08369)
- Enhancing LLM-as-a-judge to be more reliable by mitigating its evaluation bias, like [Likelihood-based mitigation (Findings of ACL 2024)](https://arxiv.org/abs/2402.15987)

In addition, I have broad interests in AI safety, including jailbreak and safe alignment.

ðŸ“¢ **I am actively looking for research internships starting in (Summer | Fall | Winter) 2025.**

## Contact
- Personal Website: [sites.google.com/view/ryutokoike/](https://sites.google.com/view/ryutokoike/)
- Twitter: [@sponddd](https://x.com/sponddd)
- email: my_first_name.my_last_name[at]nlp.c.titech.ac.jp
